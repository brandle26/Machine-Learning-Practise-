{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import and load iris using load_iris\n",
    "from sklearn.datasets import load_iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save \"bunch\" objects cantaining iris dataset and its attribute\n",
    "iris=load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prnting iris data attributes\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "#lets print out the attribute of iris object called feature_names\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "#lets print target which is the species of each observations\n",
    "#for this dataset the number represent a species of flower\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "#Now lets print the encoding scheme for species 0: \"setosa\", 1:\"versicolor\" 3:\"virginica\"\n",
    "\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#chekcing the type of feature and response\n",
    "print(type(iris.data))\n",
    "print(type(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements of working with data in scikit-learn\n",
    "1. Features and response are seperate objects\n",
    "2. Features and response should be numeric\n",
    "3. Features and Response should be numpy Arrays\n",
    "4. Feature and response should habe specific shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "#check the shape of features (first number = number of ovservations and second number=number of features)\n",
    "#scikit require the features or input to have two  number\n",
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "#check the shape of response (single number matching the number of observations)\n",
    "#scikit learn expected to have single dimension which is euql to number of response or first dimension of the feature\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Store feature matrix in X\n",
    "X=iris.data\n",
    "\n",
    "#Store target vectore in Y\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Will be using K-nearest neighbour(KNN) classification\n",
    "1. Pick a value of k\n",
    "2. search for the k observations in the training data that are \"nearest\" to the unknown iris\n",
    "3. Use the most popular response valur form the k-nearest neighbour as predicted response value for this unkown iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Scikir Learn 4-step modelling pattern\n",
    "** Step1:** Import the class you plan to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step2: ** \"Instantiate\" the \"Estimator\"\n",
    "- \"Estimator\" refers to model in scikit-learn's terminology\n",
    "- \"Instantiate\" measn makes an instance of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can specifiy tunining parameter (aka \"hyperparameter\") during this step. i.e. specify paramters for object intansiation \n",
    "- Unspecified parmaters or arguemnt are set to default by the KNeighborsClassfier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step3: ** Fit the model with data (aka Model Training)\n",
    "- Model is learning relationship between X and y\n",
    "- Occurs in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step4:** Predict the response for a new observation\n",
    "- New observations are called \"out-of-sample\" data\n",
    "- Uses infromation learnind from model training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_oneob=np.array([3,5,4,2]).reshape(1,-1)\n",
    "knn.predict(X_oneob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Returns an array\n",
    "- Can pridict for multiple observations at once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_new=np.array([[3,5,4,2],[5,4,3,2]])\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different value for K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the object using K=5\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#fit the model with data\n",
    "knn.fit(X,y)\n",
    "\n",
    "#Predict the response for new obserbation\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Instantiate the model (here using default paramters or argumtnes)\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "#fit the model with data\n",
    "logreg.fit(X,y)\n",
    "\n",
    "#predict the response for new observations\n",
    "logreg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model evaluation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Procedure 1: Train and test on the entire data set (Note this method has no official name but is common)\n",
    "1. Train the model in the ** Entire Dataset**\n",
    "2. Test the model on the ** same dataset** and evaluate how well we did by comparing ** predicted** response value with ** true** response value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the model\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "#fit the model\n",
    "logreg.fit(X,y)\n",
    "\n",
    "#now predic the response value by passing the entire feature matrix\n",
    "logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#storing the predicted response values\n",
    "y_pred=logreg.predict(X)\n",
    "\n",
    "#chekcing the number of predictions generatored\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracy\n",
    "- **Proportion ** of Correct Prediction\n",
    "- Common ** Evaluation metric ** for classification problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "#Compute Classification accuracy for the logistic regression model\n",
    "\n",
    "#import metric \n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Known as ** Training accuracy** when you train and test the model in the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For KNN where k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X,y)\n",
    "\n",
    "y_pred=knn.predict(X)\n",
    "\n",
    "#chceking training accuracy\n",
    "print(metrics.accuracy_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN where k=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X,y)\n",
    "\n",
    "y_pred=knn.predict(X)\n",
    "\n",
    "#chceking training accuracy\n",
    "print(metrics.accuracy_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it looks for only one neighbor and it is trained and has memorised the response values. This leads to KNeighborClassfier to give back 100% accuracy when same data is used for evaluating training accuracy. This means that using the smae data for evaluating the accuracy is not a very good indication of the accurcy for out-of-sample prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems of training and testing on the same data\n",
    "- The gaol is to estiamte the likely performance on ** out-of-sampl** data\n",
    "- Maximizing training accuracy rewards ** overly complex models** that won't necessarily generalize \n",
    "- Unnecessriliy complex modle ** overfit** the training data\n",
    "In this case we can say tha the model has learned th noise of the data and not necessariliy the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Procedure 2: Train/test Split\n",
    "1. Split the data into two pieces: ** a training set** and a ** testing set**\n",
    "2. Train the model on the ** training set**\n",
    "3. Test the model on the ** testing set** and evaluate how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "#Printing the shape ofX and y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 1: Split the data into training set and tesitng set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.4, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "#pint the shape of new X objects\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "#print the shape of t the new y objects\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2: Training model on the training set\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "#Step 3: make predictions on the testing set\n",
    "y_pred=logreg.predict(X_test)\n",
    "\n",
    "#compare actual respponse value (y_test) against predicted response value (y_pred)\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for KNN where k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred=knn.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for KNN for k=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred=knn.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore out of the three model KNN with k=5 is likely to be the better model for prediciing the class\n",
    "\n",
    "## Can we find better K value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets contruct a for loop to answer this question\n",
    "#try k=1 to k=25\n",
    "k_range=range(1,26)\n",
    "scores=[]\n",
    "for k in k_range:\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred=knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test,y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xa0c0638358>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw6JECwTkHloAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa0c243db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now lets plot the relationship between K value and the accuracy score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#allow plot to apper within the same cell of the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#plotting the relationship between k and testing accuracy\n",
    "plt.plot(k_range,scores)\n",
    "plt.xlabel(\"Value of K for KNN\")\n",
    "plt.ylabel(\"Testing Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Training** accuracy rises as the model complexity increase i.e. k value is low\n",
    "- ** Testing** accuracy penalize model that are too complex or not complex enough\n",
    "- For ** KNN** the model complexity is determind by the value of K (lower value=more complex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on out-of-sampel data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the model with best known parameter\n",
    "knn=KNeighborsClassifier()\n",
    "\n",
    "#train the model to fit X and y not X_traina dn y_train\n",
    "knn.fit(X,y)\n",
    "\n",
    "#make a prediction for out of sample observation\n",
    "knn.predict(np.array([3,5,4,2]).reshape(1,-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downside of train/test Split?\n",
    "\n",
    "- Provides a ** high-variance estimate** of out-of-sample accuracy. This means it can change a lot depending upon datas that happen to be in the training set vs the tesiting set\n",
    "- ** K-fold cross-validation** overcomes this limitation\n",
    "- But train/test split is still useful due to its ** flexibility ** and ** speed **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Choosing best model in sci-kit learn\n",
    "\n",
    "#### Now lets experiemnt witht he testing accuracy in order to come up with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973684210526\n"
     ]
    }
   ],
   "source": [
    "#Lets do train train split for our data\n",
    "\n",
    "#We will use different random state vlaues to split the data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=4)\n",
    "\n",
    "#check classification accuracy of KNN for k=5\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that changing random state value can change the classification accuracy. This means that the testing accuracy will depend on the data that are chosen randomly for traning and testing set.\n",
    "\n",
    "Therefore, We could create a bunch of train/test split, calculate the average testing accruacy for each and then average the resulting accruacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for K-fold cross-validation (common type)\n",
    "1. Split the dataset into K **equal** partitions (or folds)\n",
    "2. Use fold 1 as the **testing set** and union of the other folds as **training set**.\n",
    "3. Calulate **testing accuracy**.\n",
    "4. Repeat steps 2 and 3 K times, using **different fold** as the testing set each time\n",
    "5. Use the **average testing accuracy** as estimate of out-of-sample accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation recommendations\n",
    "1. K can be any number but **K=10** is generally recommended\n",
    "2. For classification problem, **stratified** sampling is reommened to create folds.\n",
    "- Each response class should be represented with equal proportion in each K fods\n",
    "- scikit-learn's cross_val_score does this by default\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validataion example: paramter tuning\n",
    "**Goal:** Select the best tuning paramter (aka \"hyperparameters\") for KNN on the iris dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.93333333  1.          1.          0.86666667  0.93333333\n",
      "  0.93333333  1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "#10 fold cross-validatiaon with k=5 for KNN (the n_neighbors parameter)\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "#cv=10 measn 10 folds cross-validataion\n",
    "scores=cross_val_score(knn,X,y,cv=10,scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "#use average accuracy as an estimate of out-of-sample accuracy\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95999999999999996, 0.95333333333333337, 0.96666666666666656, 0.96666666666666656, 0.96666666666666679, 0.96666666666666679, 0.96666666666666679, 0.96666666666666679, 0.97333333333333338, 0.96666666666666679, 0.96666666666666679, 0.97333333333333338, 0.98000000000000009, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.98000000000000009, 0.97333333333333338, 0.98000000000000009, 0.96666666666666656, 0.96666666666666656, 0.97333333333333338, 0.95999999999999996, 0.96666666666666656, 0.95999999999999996, 0.96666666666666656, 0.95333333333333337, 0.95333333333333337, 0.95333333333333337]\n"
     ]
    }
   ],
   "source": [
    "#Searching for optimal value of K for KNN\n",
    "k_range=range(1,31)\n",
    "k_scores=[]\n",
    "\n",
    "for k in k_range:\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    scores=cross_val_score(knn,X,y,cv=10,scoring=\"accuracy\")\n",
    "    k_scores.append(scores.mean())\n",
    "\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xa0c2f0ae80>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAaHRIO44BggmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa0c0640f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_range,k_scores)\n",
    "plt.xlabel(\"Value for K for KNN\")\n",
    "plt.ylabel(\"Cross-Validataion Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN algorithm higher K value produce less complex model. Therefore we will choose 20 as the optimal value of K which gives us a peak of Cross-Validatiaon accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validataion example: Model Selection\n",
    "**Goal:** Compare KNN model with logistic Regression on the iris dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validataion with best KNN model\n",
    "knn=KNeighborsClassifier(n_neighbors=20)\n",
    "print(cross_val_score(knn,X,y,cv=10,scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953333333333\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross validataion with logisitc regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "print(cross_val_score(logreg,X,y,cv=10,scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** KNN is likely a better model for this particular task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More efficient parameter tuning using GridSearchCV\n",
    "\n",
    "Allows you to define **grid of parameters** that will be **searched** using K-fold cross validation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define the parameter values that should be searched\n",
    "k_range=[i for i in range(1,31)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}\n"
     ]
    }
   ],
   "source": [
    "#create a parameter grid: map the parameter to the values that should be searched\n",
    "param_grid=dict(n_neighbors=k_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#instantiate teh grid\n",
    "grid=GridSearchCV(knn,param_grid,cv=10,scoring=\"accuracy\",n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can set n_jobs=-1 to run computation in parallel (If supported by your computer and OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the grid with data\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.96000, std: 0.05333, params: {'n_neighbors': 1},\n",
       " mean: 0.95333, std: 0.05207, params: {'n_neighbors': 2},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 3},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 4},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 5},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 6},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 7},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 8},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 9},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 10},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 11},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 12},\n",
       " mean: 0.98000, std: 0.03055, params: {'n_neighbors': 13},\n",
       " mean: 0.97333, std: 0.04422, params: {'n_neighbors': 14},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 15},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 16},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 17},\n",
       " mean: 0.98000, std: 0.03055, params: {'n_neighbors': 18},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 19},\n",
       " mean: 0.98000, std: 0.03055, params: {'n_neighbors': 20},\n",
       " mean: 0.96667, std: 0.03333, params: {'n_neighbors': 21},\n",
       " mean: 0.96667, std: 0.03333, params: {'n_neighbors': 22},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 23},\n",
       " mean: 0.96000, std: 0.04422, params: {'n_neighbors': 24},\n",
       " mean: 0.96667, std: 0.03333, params: {'n_neighbors': 25},\n",
       " mean: 0.96000, std: 0.04422, params: {'n_neighbors': 26},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 27},\n",
       " mean: 0.95333, std: 0.04269, params: {'n_neighbors': 28},\n",
       " mean: 0.95333, std: 0.04269, params: {'n_neighbors': 29},\n",
       " mean: 0.95333, std: 0.04269, params: {'n_neighbors': 30}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view complete results (list of names tuples)\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "[ 1.          0.93333333  1.          0.93333333  0.86666667  1.\n",
      "  0.86666667  1.          1.          1.        ]\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "#examine teh first tuple\n",
    "print(grid.grid_scores_[0].parameters)\n",
    "print(grid.grid_scores_[0].cv_validation_scores)\n",
    "print(grid.grid_scores_[0].mean_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
